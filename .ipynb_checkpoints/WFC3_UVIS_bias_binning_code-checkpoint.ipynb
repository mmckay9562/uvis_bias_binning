{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning UVIS Full-Frame Bias Reference File\n",
    "\n",
    "This notebook is specifically made for the WFC3/UVIS 2x2, and 3x3 binned bias reference file. However, the binning function(sci_rebin) can be used for the other various WFC3 calibration (i.e. Darks, Flats, etc.). The user will have to format the file to the appropriate shape and size, for more information about the shape and size of the binned reference files see: http://www.stsci.edu/hst/observatory/crds/SIfileInfo/WFC3/description.html\n",
    "\n",
    "### Side Notes\n",
    "- The bias binned files are made by taking the sum of the binned values\n",
    "\n",
    "- The DQ arrays are zero\n",
    "\n",
    "- The error arrays are propagated using the following equation\n",
    "For 2x2 bin\n",
    "err(binned)=sqrt(err1*err1+err2*err2+err3*err3+err4*err4)\n",
    "\n",
    "\n",
    "- For more information on the binned reference files see:\n",
    "\n",
    "http://www.stsci.edu/hst/observatory/crds/SIfileInfo/WFC3/description.html\n",
    "\n",
    "http://www.stsci.edu/hst/wfc3/documents/ISRs/2003/WFC3-2003-14.pdf\n",
    "\n",
    "http://www.stsci.edu/hst/wfc3/documents/TIRs/WFC3-TIR-2012-04.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import glob\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CD into working dir where bias data is located\n",
    "#working_dir ='/Users/mmckay/Desktop/binned_bias/'\n",
    "working_dir ='/Users/mmckay/Desktop/binned_bias/uvis_bias_binning/'\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download full-frame bias reference file from CRDS website\n",
    "## https://hst-crds.stsci.edu/\n",
    "\n",
    "### Example file\n",
    "25v1821hi_bia.fits - 2018 full-frame bias reference file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning function (Sum/Mean)\n",
    "\n",
    "## The main code came from:\n",
    "### https://scipython.com/blog/binning-a-2d-array-in-numpy/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sci_rebin(arr, new_shape, math):\n",
    "    '''\n",
    "    Bins an array to a specified porportional size\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "         arr - 2D array\n",
    "         \n",
    "         new_shape - the desired shape of the array after binning\n",
    "                    *Must be porportional to the size of the current array* \n",
    "                     (i.e 4x4 array ----> 2x2 array)\n",
    "                     \n",
    "         math - The calculation of the binned values (Sum or Mean)\n",
    "                \n",
    "                Default (sum)\n",
    "         \n",
    "    Example:\n",
    "      \n",
    "        Make an array 2x2 array\n",
    "        a = np.arange(4).reshape((2, 2))\n",
    "        print(a)\n",
    "        \n",
    "        [[0 1]\n",
    "         [2 3]]\n",
    "        \n",
    "        Bin the 2x2 array\n",
    "        \n",
    "        b = sci_rebin(a, [1,1], math='sum')\n",
    "        print(b)\n",
    "        \n",
    "        [[6]]\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    shape1 = (new_shape[0], arr.shape[0] // new_shape[0],\n",
    "             new_shape[1], arr.shape[1] // new_shape[1])\n",
    "    if math == 'sum':\n",
    "        bin_values = arr.reshape(shape1).sum(-1).sum(1)\n",
    "        return bin_values\n",
    "    elif math == 'mean':\n",
    "        bin_values = arr.reshape(shape1).mean(-1).mean(1)\n",
    "        return bin_values\n",
    "    else:\n",
    "        bin_values = arr.reshape(shape1).sum(-1).sum(1)\n",
    "        return bin_values\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing full-frame image function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uvis_ref_binning(unbinned_ref_files, binning, math):\n",
    "    '''\n",
    "    Bins WFC3/UVIS full-frame SCI, DQ and Err arrays\n",
    "    \n",
    "    The Err arrays propagated depending on the the calculation \n",
    "    of the binned values(sum or mean)\n",
    "    \n",
    "    (sum) binned error pixel= sqrt(err1*err1+err2*err2+err3*err3+err4*err4...+err9*err9)\n",
    "    (mean) binned error pixel= 1/9 sqrt(err1*err1+err2*err2+err3*err3+err4*err4...+err9*err9)\n",
    "    \n",
    "    Parameters:\n",
    "         unbinned_ref_files - Standard WFC3/UVIS full frame bias file with \n",
    "         serial and vertial overscan\n",
    "         \n",
    "         binning - The binning mode (2 for 2x2 or 3 for 3x3)\n",
    "         \n",
    "         math - The calculation of the binned values (Sum or Mean)\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "        New FITS file with binned data (6 extensions)\n",
    "        Filename: final_2x2bin_2009__bia.fits\n",
    "        No.    Name      Ver    Type      Cards   Dimensions   Format\n",
    "          0  PRIMARY       1 PrimaryHDU     730   ()      \n",
    "          1  SCI           1 ImageHDU        21   (2102, 1035)   float32   \n",
    "          2  ERR           1 ImageHDU        20   (2102, 1035)   float32   \n",
    "          3  DQ            1 ImageHDU        20   (2102, 1035)   int16   \n",
    "          4  SCI           2 ImageHDU        21   (2102, 1035)   float32   \n",
    "          5  ERR           2 ImageHDU        20   (2102, 1035)   float32   \n",
    "          6  DQ            2 ImageHDU        20   (2102, 1035)   int16  \n",
    "        \n",
    "        \n",
    "    Example:\n",
    "        2x2 binning (mean) a full-frame bias image \n",
    "        uvis_ref_binning(2010a_final_bias_ref.fits, 2, math = 'mean')\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    if binning == 3:\n",
    "        nrow=690\n",
    "        ncol=1402\n",
    "        N=9\n",
    "    \n",
    "    elif binning == 2:\n",
    "        nrow=1035\n",
    "        ncol=2102\n",
    "        N=4\n",
    "        \n",
    "    for im in unbinned_ref_files:\n",
    "        unbinned_im=fits.open(im,mode='update')\n",
    "        ref_ext1=unbinned_im[1].data\n",
    "        ref_ext2=unbinned_im[2].data\n",
    "        ref_ext3=unbinned_im[3].data\n",
    "        ref_ext4=unbinned_im[4].data\n",
    "        ref_ext5=unbinned_im[5].data\n",
    "        ref_ext6=unbinned_im[6].data\n",
    "        \n",
    "        print(ref_ext1.shape)\n",
    "        \n",
    "        #Binning the fullframe bias files  \n",
    "        #Sci extensions\n",
    "        binned_ext1=sci_rebin(ref_ext1,[nrow,ncol],math)\n",
    "        binned_ext4=sci_rebin(ref_ext4,[nrow,ncol],math)\n",
    "        \n",
    "        print(binned_ext1.shape)\n",
    "        \n",
    "        #DQ extensions\n",
    "        binned_ext3=sci_rebin(ref_ext3,[nrow,ncol],math)\n",
    "        binned_ext6=sci_rebin(ref_ext6,[nrow,ncol],math)\n",
    "    \n",
    "        \n",
    "        #Error extensions\n",
    "        #Calculate new errors for binned \n",
    "        #Square the errors\n",
    "        unbinned_err_box=ref_ext2[600:603,600:603]\n",
    "        print('unbinned error box[600:603, 600:603], extension = 2')\n",
    "        print(unbinned_err_box)\n",
    "        print('')\n",
    "        \n",
    "        sq_ext2=ref_ext2**2\n",
    "        sq_ext5=ref_ext5**2\n",
    "        \n",
    "        sq_unbinned=sq_ext2[600:603,600:603]\n",
    "        print('squared unbinned error values [600:603, 600:603], extension = 2')\n",
    "        print(sq_unbinned)\n",
    "        print('')\n",
    "        \n",
    "        #Sum of the square error\n",
    "        sqbin_ext2=sci_rebin(sq_ext2,[nrow,ncol],math='sum')\n",
    "        sqbin_ext5=sci_rebin(sq_ext5,[nrow,ncol],math='sum')\n",
    "        \n",
    "        sq_binned=sqbin_ext2[200:201,200:201]\n",
    "        print('binned(sum) squared values [200:201,200:201], extension = 2')\n",
    "        print(sq_binned)\n",
    "        print('')\n",
    "        \n",
    "        #Square root of the sum and divide by the number of unbinned pix\n",
    "        \n",
    "        if math == 'mean':\n",
    "            print('sqrt value is divided by number of binned pixels(i.e 2x2 binned N = 4)')\n",
    "            sqrt_sqbin_ext2 = np.sqrt(sqbin_ext2) / N\n",
    "            sqrt_sqbin_ext5 = np.sqrt(sqbin_ext5) / N\n",
    "            \n",
    "        else:\n",
    "            sqrt_sqbin_ext2 = np.sqrt(sqbin_ext2)\n",
    "            sqrt_sqbin_ext5 = np.sqrt(sqbin_ext5) \n",
    "        \n",
    "        sqrt_sqbin_unbinned = sqrt_sqbin_ext2[200:201,200:201]\n",
    "        print('sqrt of binned squared values, extension = 2')\n",
    "        print(sqrt_sqbin_unbinned)\n",
    "        print('')\n",
    "        \n",
    "        #Change variable\n",
    "        binned_ext2 = sqrt_sqbin_ext2\n",
    "        binned_ext5 = sqrt_sqbin_ext5\n",
    "        \n",
    "        ##--------------------------------------------------------------------------------\n",
    "         \n",
    "        unbinned_im.close()\n",
    "    \n",
    "        #Create new fits file with binned data\n",
    "        new_hdul = fits.HDUList()\n",
    "        new_hdul.append(fits.PrimaryHDU())\n",
    "        new_hdul.append(fits.ImageHDU(binned_ext1))\n",
    "        new_hdul.append(fits.ImageHDU(binned_ext2))\n",
    "        new_hdul.append(fits.ImageHDU(binned_ext3))\n",
    "        new_hdul.append(fits.ImageHDU(binned_ext4))\n",
    "        new_hdul.append(fits.ImageHDU(binned_ext5))\n",
    "        new_hdul.append(fits.ImageHDU(binned_ext6))\n",
    "        new_hdul.writeto('{}x{}bin.fits'.format(binning,binning),overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2x2 binning \n",
    "### UVIS unbinned full frame with overscan size (2070, 4206) \n",
    "### UVIS 2x2 binned images with overscan size (1035, 2102)\n",
    "\n",
    "- 2 columns are removed from the full frame serial overscan to adjust image to fit the correct size for the 2x2 array 1035,2102.\n",
    "\n",
    "- The mixed columns are not removed\n",
    "\n",
    "- Note about the bias reference files\n",
    "- The full-frame bias reference files has zero rows near the overscan. Chip1 science row 2049:2052 (3 rows) and Chip2 science row 20:23 (3 rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove columns from serial overscan\n",
    "\n",
    "### Important note (ONLY RUN ONCE!!!)\n",
    "When you run this part of the script it permanently removes two virtual overscan columns. If executed multiple times on the same file, two more columns will be deleted. Make sure to have a directory with clean files in case you make a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 4204)\n"
     ]
    }
   ],
   "source": [
    "unbin_ref=glob.glob('*.fits')\n",
    "\n",
    "for i in unbin_ref:\n",
    "    hdu = fits.open(i,mode='update')\n",
    "    chip2_sci = hdu[1].data\n",
    "    chip2_err = hdu[2].data\n",
    "    chip2_dq =  hdu[3].data\n",
    "    chip1_sci = hdu[4].data\n",
    "    chip1_err = hdu[5].data\n",
    "    chip1_dq =  hdu[6].data\n",
    "    \n",
    "    #Remove 2 cols from the virtual overscan\n",
    "    \n",
    "    hdu[1].data = np.delete(hdu[1].data, 2100,1)\n",
    "    hdu[2].data = np.delete(hdu[2].data, 2100,1)\n",
    "    hdu[3].data = np.delete(hdu[3].data, 2100,1)\n",
    "    hdu[4].data = np.delete(hdu[4].data, 2100,1)\n",
    "    hdu[5].data = np.delete(hdu[5].data, 2100,1)\n",
    "    hdu[6].data = np.delete(hdu[6].data, 2100,1)\n",
    "    \n",
    "    hdu[1].data = np.delete(hdu[1].data, 2100,1)\n",
    "    hdu[2].data = np.delete(hdu[2].data, 2100,1)\n",
    "    hdu[3].data = np.delete(hdu[3].data, 2100,1)\n",
    "    hdu[4].data = np.delete(hdu[4].data, 2100,1)\n",
    "    hdu[5].data = np.delete(hdu[5].data, 2100,1)\n",
    "    hdu[6].data = np.delete(hdu[6].data, 2100,1)\n",
    "    \n",
    "    print(hdu[1].shape)    \n",
    "    hdu.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run binning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 4204)\n",
      "(1035, 2102)\n",
      "unbinned error box[600:603, 600:603], extension = 2\n",
      "[[0.13372174 0.13412371 0.13358879]\n",
      " [0.13391082 0.13200374 0.13456431]\n",
      " [0.13428088 0.1336813  0.13199793]]\n",
      "\n",
      "squared unbinned error values [600:603, 600:603], extension = 2\n",
      "[[0.0178815  0.01798917 0.01784597]\n",
      " [0.01793211 0.01742499 0.01810755]\n",
      " [0.01803135 0.01787069 0.01742345]]\n",
      "\n",
      "binned(sum) squared values [200:201,200:201], extension = 2\n",
      "[[0.07152131]]\n",
      "\n",
      "sqrt value is divided by number of binned pixels(i.e 2x2 binned N = 4)\n",
      "sqrt of binned squared values, extension = 2\n",
      "[[0.06685867]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unbin_ref =  glob.glob('*.fits')\n",
    "uvis_ref_binning(unbin_ref, 2, math = 'sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace mixed columns with zeros\n",
    "- Due to the odd number of columns in the physical overscan, exposed columns next to the overscan are binned resulting a lower value.\n",
    "- We set the values of the mixed columns to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_2x2_files = glob.glob('2x2*.fits')\n",
    "\n",
    "for im in bin_2x2_files:\n",
    "    year= im[4:9]\n",
    "    hdu = fits.open(im,mode='update')\n",
    "    \n",
    "    sci_data1 = hdu[1].data\n",
    "    err_data1 = hdu[2].data\n",
    "    dqa_data1 = hdu[3].data\n",
    "    \n",
    "    sci_data2 = hdu[4].data\n",
    "    err_data2 = hdu[5].data\n",
    "    dqa_data2 = hdu[6].data\n",
    "    \n",
    "    #Set mixed columns to zero\n",
    "    sci_data1[:,12] = 0\n",
    "    sci_data1[:,2089] = 0\n",
    "    err_data1[:,12] = 0\n",
    "    err_data1[:,2089] = 0\n",
    "    dqa_data1[:,12] = 0\n",
    "    dqa_data1[:,2089] = 0\n",
    "    \n",
    "    sci_data2[:,12] = 0\n",
    "    sci_data2[:,2089] = 0\n",
    "    err_data2[:,12] = 0\n",
    "    err_data2[:,2089] = 0\n",
    "    dqa_data2[:,12] = 0\n",
    "    dqa_data2[:,2089] = 0  \n",
    "    \n",
    "    \n",
    "    hdu[1].data = sci_data1 \n",
    "    hdu[2].data = err_data1 \n",
    "    hdu[3].data = dqa_data1 \n",
    "    hdu[4].data = sci_data2 \n",
    "    hdu[5].data = err_data2 \n",
    "    hdu[6].data = dqa_data2 \n",
    "    \n",
    "    \n",
    "    hdu.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3x3 binning \n",
    "### UVIS unbinned full frame with overscan size (2070, 4206) \n",
    "### UVIS 3x3 binned images with overscan size (690 1402)\n",
    "\n",
    "- No columns are removed to perform the 3x3 binning\n",
    "- the mixed colums are not removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "working_dir ='/Users/mmckay/Desktop/binned_bias/test_code/'\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run binning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2070, 4206)\n",
      "(690, 1402)\n",
      "unbinned error box[600:603, 600:603], extension = 2\n",
      "[[0.09497067 0.09461706 0.09532122]\n",
      " [0.09441956 0.09462713 0.09560762]\n",
      " [0.09481271 0.09490033 0.09551942]]\n",
      "\n",
      "squared unbinned error values [600:603, 600:603], extension = 2\n",
      "[[0.00901943 0.00895239 0.00908614]\n",
      " [0.00891505 0.00895429 0.00914082]\n",
      " [0.00898945 0.00900607 0.00912396]]\n",
      "\n",
      "binned(sum) squared values [200:201,200:201], extension = 2\n",
      "[[0.0811876]]\n",
      "\n",
      "sqrt of binned squared values, extension = 2\n",
      "[[0.28493437]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unbin_ref=glob.glob('2010a_final_bias_ref 2.fits')\n",
    "uvis_ref_binning(unbin_ref,3, math='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace mixed columns with zeros\n",
    "- Due to the odd number of columns in the physical overscan, exposed columns next to the overscan are binned resulting a lower value.\n",
    "- We set the values of the mixed columns to zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        1.2090609]\n",
      " [0.        0.7061602]]\n",
      "[[-3.6933045  0.       ]\n",
      " [-3.589984   0.       ]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "bin_3x3_files = glob.glob('3x3*.fits')\n",
    "\n",
    "for im in bin_3x3_files:\n",
    "    hdu = fits.open(im,mode='update')\n",
    "    \n",
    "    sci_data1 = hdu[1].data\n",
    "    err_data1 = hdu[2].data\n",
    "    dqa_data1 = hdu[3].data\n",
    "    \n",
    "    sci_data2 = hdu[4].data\n",
    "    err_data2 = hdu[5].data\n",
    "    dqa_data2 = hdu[6].data\n",
    "\n",
    "    print(sci_data1[300:302,7:9])\n",
    "    print(sci_data1[300:302,1393:1395])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Set mixed columns to zero\n",
    "    sci_data1[:,8] = 0\n",
    "    sci_data1[:,1393] = 0\n",
    "    err_data1[:,8] = 0\n",
    "    err_data1[:,1393] = 0\n",
    "    dqa_data1[:,8] = 0\n",
    "    dqa_data1[:,1393] = 0\n",
    "    \n",
    "    sci_data2[:,8] = 0\n",
    "    sci_data2[:,1393] = 0\n",
    "    err_data2[:,8] = 0\n",
    "    err_data2[:,1393] = 0\n",
    "    dqa_data2[:,8] = 0\n",
    "    dqa_data2[:,1393] = 0\n",
    "    \n",
    "    \n",
    "    hdu[1].data = sci_data1 \n",
    "    hdu[2].data = err_data1 \n",
    "    hdu[3].data = dqa_data1 \n",
    "    hdu[4].data = sci_data2 \n",
    "    hdu[5].data = err_data2 \n",
    "    hdu[6].data = dqa_data2 \n",
    "    \n",
    "    print(sci_data1[300:302,7:9])\n",
    "    print(sci_data1[300:302,1393:1395])\n",
    "    hdu.close()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
